---
title: "Stat 1361 Homework 7"
author: "First name Last name (email address)"
date: "mm/dd/yyyy"
output:
  pdf_document: 
    df_print: paged
---


```{r, warning = FALSE, message=FALSE}
# This chunk is reserved for loading packages.
library(ISLR2)
library(tree)
library(randomForest)
library(BART)
library(gbm)
library(survival)
library(lattice)
library(splines)
library(parallel)
library(ggthemes)
library(ggplot2)
library(tidyverse)
library(glmnet)
library(dplyr)
library(magrittr)
```

# 2. ISLR Chapter 8 Conceptual Exercises 2, 4, 5  

# 8.2 (10 pts) 

Please refer to the textbook for details of this question. 

**Answers: Each of these trees are generated by splitting the data based only on one predictors (hence why the value d = 1) so the final model is formed by adding the shrunken model over and over. This is why the final model is additive.**  


# 8.4 (10 pts) 

Please refer to the textbook for details of this question. 

## 8.4.a

**Answers:**  
"![](/Users/AnateaEinhorn/Desktop/PITT 21:22/STAT LEARNING & DATA SCIENCE/HW/Homework 7/4.a.png)"

## 8.4.b 

**Answers:**  
"![](/Users/AnateaEinhorn/Desktop/PITT 21:22/STAT LEARNING & DATA SCIENCE/HW/Homework 7/4.b.png)"


# 8.5 (10 pts) 

Please refer to the textbook for details of this question. 


**Answers: Using the majority vote methods, we would assign class with most votes to X. In this examples, we would assign green to the first 4 and red to the rest. Since red receives the most (6) votes, we choose red as majority vote.**  




# 3. ISLR Chapter 8 Applied Exercises 8, 10

# 8.8 (10 pts)

Please refer to the textbook for details of this question. 

## 8.8.a  

```{r}
attach(Carseats)
set.seed(1)

train = sample(dim(Carseats)[1], dim(Carseats)[1]/2)
cs.train = Carseats[train, ]
cs.test = Carseats[-train, ]
```



## 8.8.b  
-   We get a test MSE of about 4.922

```{r}
tree.cs = tree(Sales~., data = cs.train, subset = train)
tree.cs = tree(Sales~., data = cs.train)
summary(tree.cs)

plot(tree.cs)
text(tree.cs, pretty = 0)

pred.cs = predict(tree.cs, newdata = cs.test)
mean((pred.cs - cs.test$Sales)^2)
```



## 8.8.c  
-   pruning the tree increases MSE to 5.113

```{r}
set.seed(1)
cv.cs = cv.tree(tree.cs)
plot(cv.cs$size, cv.cs$dev, type = "b")
```


```{r}
# 8 seems to be the best tree size from CV
prune.cs = prune.tree(tree.cs, best = 8)
plot(prune.cs)
text(prune.cs, pretty = 0)
```

```{r}
pred.cs = predict(prune.cs, newdata = cs.test)
mean((pred.cs - cs.test$Sales)^2)
```


## 8.8.d  
-   Results show that the variables of highest importance are price charged for carseats and quality of shelving location (both at the site.) 
-   Here the test MSE associated with the bagged regression tree is 2.605
```{r}
set.seed(1)
bag.cs = randomForest(Sales~., data = cs.train, mtry = 10, importance = TRUE)

pred.bag.cs = predict(bag.cs, newdata = cs.test)
mean((pred.bag.cs - cs.test$Sales)^2)

importance(bag.cs)

varImpPlot(bag.cs)
```



## 8.8.e  
-   test MSE is 2.960 which shows there is no improvement from using random forests over bagging
```{r}
set.seed(1)
rf.cs = randomForest(Sales~., data=cs.train, mtry = 3, importance = TRUE)

pred.rf.cs = predict(rf.cs, newdata = cs.test)
mean((pred.rf.cs - cs.test$Sales)^2)
```


## 8.8.f  
-     The MSE for BART is 1.429
```{r}
#create matrices of predictors using training and test data 
xtrain <- cs.train[,-1]
ytrain <- cs.train[,1]
xtest <- cs.test[,-1]
ytest <- cs.test[,1]

set.seed(333)
bart.fit <- gbart(xtrain, ytrain, x.test = xtest)
yhat.bart <- bart.fit$yhat.test.mean
mean((ytest - yhat.bart)^2)

```




# 8.10 (10 pts)

Please refer to the textbook for details of this question. 

## 8.10.a  

```{r}
sum(is.na(Hitters$Salary))
Hitters = Hitters[-which(is.na(Hitters$Salary)), ]
sum(is.na(Hitters$Salary))
Hitters$Salary = log(Hitters$Salary)
```



## 8.10.b  

```{r}
train = 1:200
h.train = Hitters[train,]
h.test = Hitters[-train,]
```



## 8.10.c  

```{r}
set.seed(100)
pows = seq(-10, -0.2, by = 0.1)
lambdas = 10^pows
length.lam = length(lambdas)
train.error = rep(NA, length.lam)
test.error = rep(NA, length.lam)

for (i in 1:length.lam) {
  boost.hitters = gbm(Salary~., data = h.train, distribution = "gaussian", 
                      n.trees = 1000, shrinkage = lambdas[i]) 
  pred.train = predict(boost.hitters, h.train, n.trees = 1000) 
  pred.test = predict(boost.hitters, h.test, n.trees = 1000)
  train.error[i] = mean((h.train$Salary - pred.train)^2)
  test.error[i] = mean((h.test$Salary - pred.test)^2)
}
plot(lambdas, train.error, type = "b", 
     xlab = "Shrinkage Values", ylab = "Train MSE", 
     col = "red", pch = 20)
```



## 8.10.d  

```{r}
set.seed(1)
test.err <- rep(NA, length(lambdas))
for (i in 1:length(lambdas)) {
    boost.hitters = gbm(Salary ~ ., data = h.train, distribution = "gaussian", 
                        n.trees = 1000, shrinkage = lambdas[i])
    yhat = predict(boost.hitters, h.test, n.trees = 1000)
    test.err[i] = mean((yhat - h.test$Salary)^2)
}
plot(lambdas, test.err, type = "b", xlab = "Shrinkage Values", 
     ylab = "Test MSE", col = "red", pch = 20)
```

```{r}
min(test.err)
lambdas[which.min(test.err)]
```


## 8.10.e  

```{r}
fit.1 = lm(Salary ~., data = h.train)
pred.1 = predict(fit.1, h.test)
mean((pred.1 - h.test$Salary)^2)
```

-   The test MSE for boosting is .4917 and is lower than that of linear regression as well as ridge regression. 
```{r}
x = model.matrix(Salary ~., data = h.train)
x.test = model.matrix(Salary ~., data = h.test)
y = h.train$Salary
fit.2 = glmnet(x,y,alpha=0)
pred.2 = predict(fit.2, s = .01, newx = x.test)
mean((pred.2 - h.test$Salary)^2)

```


## 8.10.f  
-   The most important variables seem to be CAtBat, PutOuts, and CWalks, respectively.
```{r}
# best lambda from part d used for shrinkage
best.boost.hitters <- gbm(Salary ~., data = h.train, 
                          distribution = "gaussian", n.trees = 1000, 
                          shrinkage = lambdas[which.min(test.err)])
summary(best.boost.hitters)
```



## 8.10.g  
-   The test MSE for bagging is .229 which is a little bit lower than the test MSE for boosting (.4917).
```{r}
set.seed(1)
bag.hitters <- randomForest(Salary ~., data = h.train, mtry = 19, ntree = 500)
yhat.bag <- predict(bag.hitters, newdata = h.test)
mean((yhat.bag - h.test$Salary)^2)
```


# 4. (20 pts)

Please refer to *STAT 1361 Homework 7.pdf* for details of this question.  


**Answers: Using regression over classification trees is usually advantageous because they are averaging and quantitative so the the error terms are easier to interpret and are more accurate. While classification trees are qualitative and have lower accuracy. We would most likely use regression before classification to split up our data optimally.**


# 5. (20 pts)

Please refer to *STAT 1361 Homework 7.pdf* for details of this question.


## 5(a)

```{r}
hw7 <- read.csv("/Users/AnateaEinhorn/Desktop/PITT 21:22/STAT LEARNING & DATA SCIENCE/HW/Homework 7/HW7train.csv", header = T)

set.seed(100)
train7 <- hw7%>%sample_frac(size = .9)
test7 <- hw7%>%setdiff(train7)
```


## 5(b)
-   X1 is above 3 so it would be more important than the others.
```{r}
# train model
rf <- randomForest(y ~., train7, mtry = 10, importance = TRUE)
importance(rf)

#plot
par(mfrow = c(3,1))
plot(rf$importance[,1],type="b",axes=F,ann=F,ylim=c(0,max(rf$importance[,1])+1))
     axis(1,at=1:10,lab=names(train7)[-1])
     axis(2,at=seq(0,max(rf$importance)+1,0.25),las=1)
     box()
```



## 5(c)  
-   X1 doesn't really seem important compared the other predictors - overall they seem to have similar importance with the 9 remaining predictors raising to the level it was in part b.
```{r}
mse.perm = rep(NA, 10)

for (i in 1:10){
    train.perm <- sample(train7[, i+1], size = 900, replace = FALSE)
    train <- train7[,-(i+1)]
    train <- add_column(train, train.perm, .after = i)
    names(train)[i+1] <- paste0("X", i)
    rf <- randomForest(y ~., data = train, mtry = 10, importance = TRUE)
    pred <- predict(rf, newdata = test7)
    mse.perm[i] <- mean((pred - test7$y)^2)
}

 plot(mse.perm,type="b",axes=F,ann=F,ylim=c(0,max(mse.perm)+1))
     axis(1,at=1:10,lab=names(train7)[-1])
     axis(2,at=seq(0,max(mse.perm)+1,0.25),las=1)
     box()
```



## 5(d)  

```{r}
set.seed(100)
n = length(train7$X1)
PermSamples = rep(0,900)
mse.loo = rep(0,10)

for (i in 2:11){
  train_loo = train7[,-i]
  
  rf = randomForest(y ~., data = train_loo, mtry = 5, importance = TRUE)
  
  yhat.rf = predict(rf, new_data = test7)
  mse.loo[i-1] = mean((yhat.rf - test7$y)^2)
}
```


## 5(e)  
-   Only one that stands out is X1 rest are about the same 
```{r}
par(mfrow=c(3,1))
plot(rf$importance[,1],type="b",axes=F,ann=F,ylim=c(0,max(rf$importance[,1])+1))
     axis(1,at=1:10,lab=names(train7)[-1])
     axis(2,at=seq(0,max(rf$importance)+1,0.25),las=1)
     box()
plot(mse.perm,type="b",axes=F,ann=F,ylim=c(0,max(mse.perm)+1))
     axis(1,at=1:10,lab=names(train7)[-1])
     axis(2,at=seq(0,max(mse.perm)+1,0.25),las=1)
     box()
plot(mse.loo,type="b",axes=F,ann=F,ylim=c(0,max(mse.loo)+1))
     axis(1,at=1:10,lab=names(train7)[-1])
     axis(2,at=seq(0,max(mse.loo)+1,0.25),las=1)
box()
```




# 6. (20 pts)

Please refer to *STAT 1361 Homework 7.pdf* for details of this question.

## 6(a)

```{r}
# create training
set.seed(1)
df.train = as.data.frame(matrix(rnorm(100*10), nrow = 100, ncol = 10))
names(df.train) = paste0('x', 1:(ncol(df.train)))
eps = rnorm(100, 0, 0.25)
y = df.train$x1 + df.train$x2 + df.train$x3 + df.train$x4 + df.train$x5 + 
  df.train$x6 + df.train$x7 + df.train$x8 + df.train$x9 + df.train$x10 + eps
df.train = df.train %>% mutate(y=y)
```


## 6(b)

```{r}
# create test 
x.test = matrix(rnorm(10000*10), nrow = 10000, ncol = 10)
df.test = as.data.frame(x.test)
names(df.test) = paste0('x', 1:(ncol(df.test)))
eps.test = rnorm(100, 0, 0.25)
y.test = df.test$x1 + df.test$x2 + df.test$x3 + df.test$x4 + df.test$x5 + 
  df.test$x6 + df.test$x7 + df.test$x8 + df.test$x9 + df.test$x10 + eps.test
df.test = df.test %>% mutate(y=y.test)
```


## 6(c)  

```{r}
set.seed(1)
bag.mod = randomForest(y ~., data = df.train, mtry = 10, importance = T)

yhat.bag = predict(bag.mod, newdata = df.test)
mean((yhat.bag - y.test)^2)

#random forest
set.seed(1)
rf.mod = randomForest(y ~., data = df.train, mtry = 3, importance = T)

yhat.rf = predict(rf.mod, newdata = df.test)
mean((yhat.rf - y.test)^2)
```


## 6(d)  
-   Average Bagged Error (.25) =  5.095114
-   Average RF Error (.25) = 4.587585
```{r}
#.25
#repeating a and c 50 times
err_bag_0.25 = list()
err_rf_0.25 = list()
for (i in 1:50){
  set.seed(1)
  df.train = as.data.frame(matrix(rnorm(100*10), nrow = 100, ncol = 10))
  names(df.train) = paste0('x', 1:(ncol(df.train)))
  eps = rnorm(100, 0, 0.25)
  y = df.train$x1 + df.train$x2 + df.train$x3 + df.train$x4 + df.train$x5 + 
    df.train$x6 + df.train$x7 + df.train$x8 + df.train$x9 + df.train$x10 + eps
  df.train = df.train %>% mutate(y=y)
  
  
  x.test = matrix(rnorm(10000*10), nrow = 10000, ncol = 10)
  df.test = as.data.frame(x.test)
  names(df.test) = paste0('x', 1:(ncol(df.test)))
  eps.test = rnorm(100, 0, 0.25)
  y.test = df.test$x1 + df.test$x2 + df.test$x3 + df.test$x4 + df.test$x5 + 
    df.test$x6 + df.test$x7 + df.test$x8 + df.test$x9 + df.test$x10 + eps.test
  df.test = df.test %>% mutate(y=y.test)
  
  bag.mod = randomForest(y ~., data = df.train, mtry = 10, importance = T)
  
  yhat.bag = predict(bag.mod, newdata = df.test)
  err_bag_0.25[i] = mean((yhat.bag - y.test)^2)
  
  rf.mod = randomForest(y ~., data = df.train, mtry = 3, importance = T)
  
  yhat.rf = predict(rf.mod, newdata = df.test)
  err_rf_0.25[i] = mean((yhat.rf - y.test)^2)
}

mean(unlist(err_bag_0.25))
mean(unlist(err_rf_0.25))

```

-   Average Bagged Error (1) = 5.671185
-   Average RF Error (1) = 5.568607
```{r}
#1
err_bag_1 = list()
err_rf_1 = list()
for (i in 1:50){
  set.seed(1)
  df.train = as.data.frame(matrix(rnorm(100*10), nrow = 100, ncol = 10))
  names(df.train) = paste0('x', 1:(ncol(df.train)))
  eps = rnorm(100, 0, 1)
  y = df.train$x1 + df.train$x2 + df.train$x3 + df.train$x4 + df.train$x5 + 
    df.train$x6 + df.train$x7 + df.train$x8 + df.train$x9 + df.train$x10 + eps
  df.train = df.train %>% mutate(y=y)
  
  
  x.test = matrix(rnorm(10000*10), nrow = 10000, ncol = 10)
  df.test = as.data.frame(x.test)
  names(df.test) = paste0('x', 1:(ncol(df.test)))
  eps.test = rnorm(100, 0, 1)
  y.test = df.test$x1 + df.test$x2 + df.test$x3 + df.test$x4 + df.test$x5 + 
    df.test$x6 + df.test$x7 + df.test$x8 + df.test$x9 + df.test$x10 + eps.test
  df.test = df.test %>% mutate(y=y.test)
  
  bag.mod = randomForest(y ~., data = df.train, mtry = 10, importance = T)
  
  yhat.bag = predict(bag.mod, newdata = df.test)
  err_bag_1[i] = mean((yhat.bag - y.test)^2)
  
  rf.mod = randomForest(y ~., data = df.train, mtry = 3, importance = T)
  
  yhat.rf = predict(rf.mod, newdata = df.test)
  err_rf_1[i] = mean((yhat.rf - y.test)^2)
}

mean(unlist(err_bag_1))
mean(unlist(err_rf_1))
```


-   Average Bagged Error (5) = 35.09329
-   Average RF Error (5) = 34.05728
```{r}
#5
err_bag_5 = list()
err_rf_5 = list()
for (i in 1:50){
  set.seed(1)
  df.train = as.data.frame(matrix(rnorm(100*10), nrow = 100, ncol = 10))
  names(df.train) = paste0('x', 1:(ncol(df.train)))
  eps = rnorm(100, 0, 5)
  y = df.train$x1 + df.train$x2 + df.train$x3 + df.train$x4 + df.train$x5 + 
    df.train$x6 + df.train$x7 + df.train$x8 + df.train$x9 + df.train$x10 + eps
  df.train = df.train %>% mutate(y=y)
  
  x.test = matrix(rnorm(10000*10), nrow = 10000, ncol = 10)
  df.test = as.data.frame(x.test)
  names(df.test) = paste0('x', 1:(ncol(df.test)))
  eps.test = rnorm(100, 0, 5)
  y.test = df.test$x1 + df.test$x2 + df.test$x3 + df.test$x4 + df.test$x5 + 
    df.test$x6 + df.test$x7 + df.test$x8 + df.test$x9 + df.test$x10 + eps.test
  df.test = df.test %>% mutate(y=y.test)
  
  bag.mod = randomForest(y ~., data = df.train, mtry = 10, importance = T)
  
  yhat.bag = predict(bag.mod, newdata = df.test)
  err_bag_5[i] = mean((yhat.bag - y.test)^2)
  
  rf.mod = randomForest(y ~., data = df.train, mtry = 3, importance = T)
  
  yhat.rf = predict(rf.mod, newdata = df.test)
  err_rf_5[i] = mean((yhat.rf - y.test)^2)
}

mean(unlist(err_bag_5))
mean(unlist(err_rf_5))
```

-   Average Bagged Error (10) = 126.9354
-   Average RF Error (10) = 124.9004
```{r}
#10
err_bag_10 = list()
err_rf_10 = list()
for (i in 1:50){
  set.seed(1)
  df.train = as.data.frame(matrix(rnorm(100*10), nrow = 100, ncol = 10))
  names(df.train) = paste0('x', 1:(ncol(df.train)))
  eps = rnorm(100, 0, 10)
  y = df.train$x1 + df.train$x2 + df.train$x3 + df.train$x4 + df.train$x5 + 
    df.train$x6 + df.train$x7 + df.train$x8 + df.train$x9 + df.train$x10 + eps
  df.train = df.train %>% mutate(y=y)
  
  
  x.test = matrix(rnorm(10000*10), nrow = 10000, ncol = 10)
  df.test = as.data.frame(x.test)
  names(df.test) = paste0('x', 1:(ncol(df.test)))
  eps.test = rnorm(100, 0, 10)
  y.test = df.test$x1 + df.test$x2 + df.test$x3 + df.test$x4 + df.test$x5 + 
    df.test$x6 + df.test$x7 + df.test$x8 + df.test$x9 + df.test$x10 + eps.test
  df.test = df.test %>% mutate(y=y.test)
  
  bag.mod = randomForest(y ~., data = df.train, mtry = 10, importance = T)
  
  yhat.bag = predict(bag.mod, newdata = df.test)
  err_bag_10[i] = mean((yhat.bag - y.test)^2)
  
  rf_mod = randomForest(y ~., data = df.train, mtry = 3, importance = T)
  
  yhat.rf = predict(rf_mod, newdata = df.test)
  err_rf_10[i] = mean((yhat.rf - y.test)^2)
}

mean(unlist(err_bag_10))
mean(unlist(err_rf_10))
```

-   Average Bagged Error (15) = 278.2791
-   Average RF Error (15) = 275.5194
```{r}
#15
err_bag_15 = list()
err_rf_15 = list()
for (i in 1:50){
  set.seed(1)
  df.train = as.data.frame(matrix(rnorm(100*10), nrow = 100, ncol = 10))
  names(df.train) = paste0('x', 1:(ncol(df.train)))
  eps = rnorm(100, 0, 15)
  y = df.train$x1 + df.train$x2 + df.train$x3 + df.train$x4 + df.train$x5 + 
    df.train$x6 + df.train$x7 + df.train$x8 + df.train$x9 + df.train$x10 + eps
  df.train = df.train %>% mutate(y=y)
  
  
  x.test = matrix(rnorm(10000*10), nrow = 10000, ncol = 10)
  df.test = as.data.frame(x.test)
  names(df.test) = paste0('x', 1:(ncol(df.test)))
  eps.test = rnorm(100, 0, 15)
  y.test = df.test$x1 + df.test$x2 + df.test$x3 + df.test$x4 + df.test$x5 + 
    df.test$x6 + df.test$x7 + df.test$x8 + df.test$x9 + df.test$x10 + eps.test
  df.test = df.test %>% mutate(y=y.test)
  
  bag.mod = randomForest(y ~., data = df.train, mtry = 10, importance = T)
  
  yhat.bag = predict(bag.mod, newdata = df.test)
  err_bag_15[i] = mean((yhat.bag - y.test)^2)
  
  rf.mod = randomForest(y ~., data = df.train, mtry = 3, importance = T)
  
  yhat.rf = predict(rf.mod, newdata = df.test)
  err_rf_15[i] = mean((yhat.rf - y.test)^2)
}

mean(unlist(err_bag_15))
mean(unlist(err_rf_15))
```

-   Average Bagged Error (25) = 770.6005
-   Average RF Error (25) = 758.9919
```{r}
#25
err_bag_25 = list()
err_rf_25 = list()
for (i in 1:50){
  set.seed(1)
  df.train = as.data.frame(matrix(rnorm(100*10), nrow = 100, ncol = 10))
  names(df.train) = paste0('x', 1:(ncol(df.train)))
  eps = rnorm(100, 0, 25)
  y = df.train$x1 + df.train$x2 + df.train$x3 + df.train$x4 + df.train$x5 + 
    df.train$x6 + df.train$x7 + df.train$x8 + df.train$x9 + df.train$x10 + eps
  df.train = df.train %>% mutate(y=y)
  
  
  x.test = matrix(rnorm(10000*10), nrow = 10000, ncol = 10)
  df.test = as.data.frame(x.test)
  names(df.test) = paste0('x', 1:(ncol(df.test)))
  eps.test = rnorm(100, 0, 25)
  y.test = df.test$x1 + df.test$x2 + df.test$x3 + df.test$x4 + df.test$x5 + 
    df.test$x6 + df.test$x7 + df.test$x8 + df.test$x9 + df.test$x10 + eps.test
  df.test = df.test %>% mutate(y=y.test)
  
  bag.mod = randomForest(y ~., data = df.train, mtry = 10, importance = T)
  
  yhat.bag = predict(bag.mod, newdata = df.test)
  err_bag_25[i] = mean((yhat.bag - y.test)^2)
  
  rf.mod = randomForest(y ~., data = df.train, mtry = 3, importance = T)
  
  yhat.rf = predict(rf.mod, newdata = df.test)
  err_rf_25[i] = mean((yhat.rf - y.test)^2)
}

mean(unlist(err_bag_25))
mean(unlist(err_rf_25))
```




## 6(e)  
-   Random Forest works pretty well when compared to bagging, specifically when the data is noisier.
-   The errors are larger when sigma increases due to more noise, the one ecception to this was at sigma = .25 (here, bagging was better than random forest)
```{r}
sigma = c(0.25,1,5,10,15,25)
#if the difference is positive then the bagged has higher error than RF
dif.error = c(mean(unlist(err_bag_0.25)) - mean(unlist(err_rf_0.25)),
              mean(unlist(err_bag_1)) - mean(unlist(err_rf_1)),
              mean(unlist(err_bag_5)) - mean(unlist(err_rf_5)),
              mean(unlist(err_bag_10)) - mean(unlist(err_rf_10)),
              mean(unlist(err_bag_15)) - mean(unlist(err_rf_15)),
              mean(unlist(err_bag_25)) - mean(unlist(err_rf_25)))
df_plot = data.frame(sigma, dif.error)

#plot 
#sigma on x 
df_plot %>% ggplot() +
geom_line(aes(sigma, dif.error)) +
geom_point(aes(sigma, dif.error)) +
labs(x = "Sigma", y = "Difference in Test Error", title = "Difference between Bagged Test Error and RF vs. Sigma") +
theme_bw()
```










